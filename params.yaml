Seq2SeqTrainingArguments:
  eval_strategy: "steps"
  eval_steps: 500
  per_device_train_batch_size: 16
  per_device_eval_batch_size: 16
  num_train_epochs: 3
  save_steps: 1000
  save_total_limit: 3
  logging_steps: 500
  predict_with_generate: true
  fp16: true
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import*\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n",
    "    model_ckpt: Path\n",
    "    eval_strategy: str\n",
    "    eval_steps: int\n",
    "    per_device_train_batch_size: int\n",
    "    per_device_eval_batch_size:  int\n",
    "    num_train_epochs: int\n",
    "    save_steps: int\n",
    "    save_total_limit: int\n",
    "    logging_steps: int\n",
    "    predict_with_generate: bool\n",
    "    fp16: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpellingCorrection.constants import*\n",
    "from SpellingCorrection.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "from dataclasses import dataclass \n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath = CONFIG_FILE_PATH,\n",
    "            params_filepath = PARAMS_FILE_PATH):\n",
    "        \n",
    "            self.config = read_yaml(config_filepath)\n",
    "            self.params = read_yaml(params_filepath)\n",
    "\n",
    "            create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self)-> ModelTrainerConfig:\n",
    "        config= self.config.model_trainer\n",
    "        params = self.params.Seq2SeqTrainingArguments\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config= ModelTrainerConfig(\n",
    "            root_dir = config.root_dir,\n",
    "            data_path = config.data_path,\n",
    "            model_ckpt = config.model_ckpt,\n",
    "\n",
    "            eval_strategy = params.eval_strategy,\n",
    "            eval_steps = params.eval_steps,\n",
    "            per_device_train_batch_size = params.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size = params.per_device_eval_batch_size,\n",
    "            num_train_epochs = params.num_train_epochs,\n",
    "            save_steps = params.save_steps,\n",
    "            save_total_limit = params.save_total_limit,\n",
    "            logging_steps = params.logging_steps,\n",
    "            predict_with_generate = params.predict_with_generate,\n",
    "            fp16 = params.fp16\n",
    "            \n",
    "        )\n",
    "        return model_trainer_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import pipeline, set_seed, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from datasets import load_dataset, load_from_disk, load_metric\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "from transformers import Seq2SeqTrainer\n",
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def train(self):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained(self.config.model_ckpt)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(self.config.model_ckpt).to(device)\n",
    "        seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "\n",
    "        dataset_spelling_correction= load_from_disk(self.config.data_path)\n",
    "\n",
    "        training_args = Seq2SeqTrainingArguments(\n",
    "            output_dir = self.config.root_dir,\n",
    "            eval_strategy = self.config.eval_strategy,\n",
    "            per_device_train_batch_size = self.config.per_device_train_batch_size,\n",
    "            per_device_eval_batch_size = self.config.per_device_eval_batch_size,\n",
    "            predict_with_generate = self.config.predict_with_generate,\n",
    "            num_train_epochs = self.config.num_train_epochs,\n",
    "            save_steps = self.config.save_steps,\n",
    "            save_total_limit = self.config.save_total_limit,\n",
    "            logging_steps = self.config.logging_steps,\n",
    "            fp16 = self.config.fp16\n",
    "        )\n",
    "        \n",
    "        trainer = Seq2SeqTrainer(\n",
    "            model = model,\n",
    "            tokenizer = tokenizer,\n",
    "            args = training_args,\n",
    "            data_collator= seq2seq_data_collator,\n",
    "            train_dataset = dataset_spelling_correction[\"train\"],\n",
    "            eval_dataset = dataset_spelling_correction[\"validation\"]\n",
    "        )\n",
    "        trainer.train()\n",
    "\n",
    "        #save model:\n",
    "        model.save_pretrained(os.path.join(self.config.root_dir,\"bartpho-spelling-correction\"))\n",
    "        tokenizer.save_pretrained(os.path.join(self.config.root_dir,\"bartpho-spelling-correction-tokenizer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    model_trainer_config = ModelTrainer(config=model_trainer_config)\n",
    "    model_trainer_config.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
